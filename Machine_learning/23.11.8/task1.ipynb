{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对孩子很有帮助，印刷质量也很好。但是：NUM、文字错误的地方很多 NUM、CD制作很粗糙。\n",
      "TB上只要NUMNUMNUM，要是这里能降到NUMNUMNUM我肯定买，毕竟在JOYO买了很多东西，信得过\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "train_comment = re.sub('\\d', 'NUM', '对孩子很有帮助，印刷质量也很好。但是：1、文字错误的地方很多 2、CD制作很粗糙。')\n",
    "print(train_comment)\n",
    "train_comment = re.sub('\\d', 'NUM', 'TB上只要330，要是这里能降到350我肯定买，毕竟在JOYO买了很多东西，信得过')\n",
    "print(train_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\LLeavee\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.591 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[全模式]:  机器/ 学习/ 导论/ 是/ 大数/ 数据/ 与/ 互联/ 互联网/ 联网/ 学院/ 的/ 一门/ 专业/ 选修/ 选修课/ 修课\n",
      "[精确模式]:  机器/ 学习/ 导论/ 是/ 大/ 数据/ 与/ 互联网/ 学院/ 的/ 一门/ 专业/ 选修课\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "# 全模式\n",
    "seg_list = jieba.cut(\"机器学习导论是大数据与互联网学院的一门专业选修课\", cut_all=True)\n",
    "print(\"[全模式]: \", \"/ \".join(seg_list))  # 全模式\n",
    "# 精确模式\n",
    "seg_list = jieba.cut(\"机器学习导论是大数据与互联网学院的一门专业选修课\", cut_all=False)\n",
    "print(\"[精确模式]: \", \"/ \".join(seg_list))  # 精确模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "太好听了.德国造的.不买很可惜.我已经买了,不在J0YO,只要118元\n",
      "包装盒破裂,拆开了才发现!\n",
      "很好！35元绝对超值。内容好，又很有趣，而且是中文配音的，很适合儿童\n",
      "------------------\n",
      "太好听了.德国造的.不买很可惜.我已经买了,不在J0YO,只要118元\n",
      "包装盒破裂OOV拆开了才发现!\n",
      "很好！35元绝对超值OOV内容好OOV又很有趣OOV而且是中文配音的OOV很适合儿童\n",
      "------------------\n",
      "太好听了.德国造的.不买很可惜.我已经买了,不在J0YO,只要118元\n",
      "包装盒破裂OOV拆开了才发现!\n",
      "很好！ NUM  NUM 元绝对超值OOV内容好OOV又很有趣OOV而且是中文配音的OOV很适合儿童\n",
      "------------------\n",
      "太好听了.德国造的.不买很可惜.我已经买了,不在J0YO,只要118元\n",
      "包装盒破裂OOV拆开了才发现!\n",
      "很好！ NUM  NUM 元绝对超值OOV内容好OOV又很有趣OOV而且是中文配音的OOV很适合儿童\n",
      "------------------\n",
      "['num' '不买很可惜' '不在j0yo' '元绝对超值oov内容好oov又很有趣oov而且是中文配音的oov很适合儿童'\n",
      " '包装盒破裂oov拆开了才发现' '只要118元' '太好听了' '很好' '德国造的' '我已经买了']\n",
      "(3, 10)\n",
      "  (0, 5)\t0.4082482904638631\n",
      "  (0, 2)\t0.4082482904638631\n",
      "  (0, 9)\t0.4082482904638631\n",
      "  (0, 1)\t0.4082482904638631\n",
      "  (0, 8)\t0.4082482904638631\n",
      "  (0, 6)\t0.4082482904638631\n",
      "  (1, 4)\t1.0\n",
      "  (2, 3)\t0.4082482904638631\n",
      "  (2, 0)\t0.8164965809277261\n",
      "  (2, 7)\t0.4082482904638631\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def clean_symbols(text):\n",
    "    text = re.sub('[!! ]+', \"!\", text)\n",
    "    text = re.sub('[?? ]+', \"?\", text)\n",
    "    text = re.sub(\"[a-zA-Z#$%&\\'()*+,-./:;：<=>@，。★、…【】《》＂“”‘’[\\\\]^_`{|}~]+\", \"OOV\", text)\n",
    "    return re.sub(\"\\s+\", \" \", text)\n",
    "\n",
    "\n",
    "comment1 = '太好听了.德国造的.不买很可惜.我已经买了,不在J0YO,只要118元'\n",
    "comment2 = '包装盒破裂,拆开了才发现!'\n",
    "comment3 = '很好！35元绝对超值。内容好，又很有趣，而且是中文配音的，很适合儿童'\n",
    "print(comment1+'\\n'+comment2+'\\n'+comment3)\n",
    "\n",
    "print('------------------')\n",
    "commenti = clean_symbols(comment1)\n",
    "comment2 = clean_symbols(comment2)\n",
    "comment3 = clean_symbols(comment3)\n",
    "print(comment1+'\\n'+comment2+'\\n'+comment3)\n",
    "print('------------------')\n",
    "commenti = re.sub('\\d', ' NUM ', comment1)\n",
    "comment2 = re.sub('\\d', ' NUM ', comment2)\n",
    "comment3 = re.sub('\\d', ' NUM ', comment3)\n",
    "print(comment1+'\\n'+comment2+'\\n'+comment3)\n",
    "print('------------------')\n",
    "\n",
    "cut1 = jieba.cut(comment1)\n",
    "cut2 = jieba.cut(comment2)\n",
    "cut3 = jieba.cut(comment3)\n",
    "seg = [word for word in cut1]\n",
    "comnent1 = \" \".join(seg)\n",
    "seg = [word for word in cut2]\n",
    "comnent2 = \" \".join(seg)\n",
    "seg = [word for word in cut3]\n",
    "Comment3 = \" \".join(seg)\n",
    "print(comment1+'\\n'+comment2+'\\n'+comment3)\n",
    "print('------------------')\n",
    "\n",
    "corpus=[comment1,comment2,comment3]\n",
    "vectorizer=TfidfVectorizer()\n",
    "X=vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "# 如果找不到get_feature_names_out()请使用get_feature_names()\n",
    "# print(vectorizer.get_feature_names())\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      0.67      0.80         3\n",
      "     class 1       0.50      1.00      0.67         1\n",
      "     class 2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.50      0.56      0.49         5\n",
      "weighted avg       0.70      0.60      0.61         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = [1, 2, 0, 0, 0]\n",
    "y_gred = [1, 1, 0, 0, 2]\n",
    "target_names = [\"class 0\", \"class 1\", \"class 2\"]\n",
    "print(classification_report(y_true, y_gred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
