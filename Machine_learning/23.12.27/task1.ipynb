{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### relu激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实现relu函数\n",
    "def relu(x):\n",
    "    \"\"\"\n",
    "    input: x(ndarray)\n",
    "    output: relu(x)(ndarray)\n",
    "    \"\"\"\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "x = np.array([-1, 1, 2])\n",
    "relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid函数及其偏导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现sigmoid函数\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    input: x(ndarray)\n",
    "    output: sigmoid(x)(ndarray)\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "# 计算sigmoid函数偏导\n",
    "def deriv_sigmoid(x):\n",
    "    \"\"\"\n",
    "    input: x(ndarray)\n",
    "    output: sigmoid(x)(ndarray)\n",
    "    \"\"\"\n",
    "    m, n = np.shape(x)\n",
    "    out = np.mat(np.zeros((m, n)))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            out[i, j] = sigmoid(x[i, j]) * (1 - sigmoid(x[i, j]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bp神经网络训练方法\n",
    "def bp_brain(feature, label, n_hidden, maxcycle, alpha, n_output):\n",
    "    \"\"\"\n",
    "    计算隐含层的输入\n",
    "    input: feature(mat):特征\n",
    "            label(mat):标签\n",
    "            n_hidden(int):隐含层的节点个数\n",
    "            maxCycle(int):最大的迭代次数\n",
    "            alpha(float):学习率\n",
    "            n_output(int):输出层的节点个数\n",
    "    output: w0(mat):输入层到隐含层之间的权重\n",
    "            b0(mat):输入层到隐含层之间的偏置\n",
    "            w1(mat):隐含层到输出层之间的权重\n",
    "            b1(mat):隐含层到输出层之间的偏置\n",
    "    \"\"\"\n",
    "    m, n = np.shape(feature)\n",
    "    # 初始化\n",
    "    w0 = np.mat(np.random.rand(n, n_hidden))\n",
    "    w0 = w0 * (8.0 * sqrt(6) / sqrt(n + n_hidden)) - np.mat(np.ones((n, n_hidden))) * (\n",
    "        4.0 * sqrt(6) / sqrt(n + n_hidden)\n",
    "    )\n",
    "    b0 = np.mat(np.random.rand(1, n_hidden))\n",
    "    b0 = b0 * (8.0 * sqrt(6) / sqrt(n + n_hidden)) - np.mat(np.ones((1, n_hidden))) * (\n",
    "        4.0 * sqrt(6) / sqrt(n + n_hidden)\n",
    "    )\n",
    "    w1 = np.mat(np.random.rand(n_hidden, n_output))\n",
    "    w1 = w1 * (8.0 * sqrt(6) / sqrt(n_hidden + n_output)) - np.mat(\n",
    "        np.ones((n_hidden, n_output))\n",
    "    ) * (4.0 * sqrt(6) / sqrt(n_hidden + n_output))\n",
    "    b1 = np.mat(np.random.rand(1, n_output))\n",
    "    b1 = b1 * (8.0 * sqrt(6) / sqrt(n_hidden + n_output)) - np.mat(\n",
    "        np.ones((1, n_output))\n",
    "    ) * (4.0 * sqrt(6) / sqrt(n_hidden + n_output))\n",
    "    # 训练\n",
    "    i = 0\n",
    "    while i <= maxcycle:\n",
    "        # TODO\n",
    "        # 前向传播\n",
    "        # 计算隐含层的输入\n",
    "        hidden_input = feature * w0 + np.tile(b0, (m, 1))\n",
    "        # 计算隐含层的输出\n",
    "        hidden_output = relu(hidden_input)\n",
    "        # 计算输出层的输入\n",
    "        output_in = hidden_output * w1 + np.tile(b1, (m, 1))\n",
    "        # 计算输出层的输出\n",
    "        output_out = relu(output_in)\n",
    "\n",
    "        # TODO\n",
    "        # 反向传播\n",
    "        # 隐藏层到输出层之间的残差\n",
    "        delta_output = -np.multiply(\n",
    "            (label - output_out), np.multiply(output_out, (1 - output_out))\n",
    "        )\n",
    "        # 输入层到隐含层之间的残差\n",
    "        delta_hidden = np.multiply(\n",
    "            delta_output * w1.T, np.multiply(hidden_output, (1 - hidden_output))\n",
    "        )\n",
    "        # 更新隐含层到输出层之间的权重和偏置\n",
    "        w1 = w1 - alpha * (hidden_output.T * delta_output)\n",
    "        b1 = b1 - alpha * np.sum(delta_output, axis=0) / m\n",
    "        # 更新输入层到隐含层之间的权重和偏置\n",
    "        w0 = w0 - alpha * (feature.T * delta_hidden)\n",
    "        b0 = b0 - alpha * np.sum(delta_hidden, axis=0) / m\n",
    "\n",
    "        i += 1\n",
    "    return w0, b0, w1, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算隐藏层的输入函数\n",
    "def hidden_in(feature, w0, b0):\n",
    "    m = np.shape(feature)[0]\n",
    "    hidden_in = feature * w0\n",
    "    for i in range(m):\n",
    "        hidden_in[i,] += b0\n",
    "    return hidden_in\n",
    "\n",
    "\n",
    "# 计算隐藏层的输出函数\n",
    "def hidden_out(hidden_in):\n",
    "    hidden_out = sigmoid(hidden_in)\n",
    "    return hidden_out\n",
    "\n",
    "\n",
    "# 计算输出层的输入函数\n",
    "def predict_in(hidden_out, w1, b1):\n",
    "    m = np.shape(hidden_out)[0]\n",
    "    predict_in = hidden_out * w1\n",
    "    for i in range(m):\n",
    "        predict_in[i,] += b1\n",
    "    return predict_in\n",
    "\n",
    "\n",
    "# 计算输出层的输出函数\n",
    "def predict_out(predict_in):\n",
    "    predict_out = sigmoid(predict_in)\n",
    "    return predict_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于Dropout方法输出存在随机性，我们已经设置好随机种子，你只要完成Dropout方法的实现即可\n",
    "class Dropout:\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        \"\"\"\n",
    "        前向传播中self，mask会随机生成和x形状相同的数组，\n",
    "        并将其中小于dropout_ratio的元素设为True，其余为False\n",
    "        x为一个列表\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        if train_flg:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1.0 - self.dropout_ratio)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        前向传播时传递了信号的神经元，\n",
    "        反向传播时按原样传递信号。\n",
    "        前向传播没有传递信号的神经元，\n",
    "        反向传播时信号就停在那里。\n",
    "        dout为一个列表。\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 0 0 0 4 0 6 0 0 0]\n",
      "[0 0 0 0 4 0 6 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(x)\n",
    "dropout = Dropout(0.5)\n",
    "print(dropout.forward(x))\n",
    "print(dropout.backward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 鸢尾花数据集分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def iris_predict(train_sample, train_label, test_sample):\n",
    "    \"\"\"\n",
    "    实现功能：1.训练神经网络\n",
    "             2.预测测试样本的标签\n",
    "    输入：train_sample(ndarry):训练样本的特征\n",
    "            train_label(ndarry):训练样本的标签\n",
    "            test_sample(ndarry):测试样本的特征\n",
    "    return: test_predict(ndarry):测试样本的预测标签\n",
    "    \"\"\"\n",
    "    # 使用交叉验证寻找最佳参数\n",
    "    parameters = {\n",
    "        \"solver\": [\"lbfgs\"],\n",
    "        \"max_iter\": [500, 1000, 1500],\n",
    "        \"alpha\": 10.0 ** -np.arange(1, 7),\n",
    "        \"hidden_layer_sizes\": np.arange(5, 12),\n",
    "        \"random_state\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    }\n",
    "    clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\n",
    "    clf.fit(train_sample, train_label)\n",
    "    test_predict = clf.predict(test_sample)\n",
    "    # 打印最佳参数\n",
    "    print(\"Best parameters found: \", clf.best_params_)\n",
    "    return test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'alpha': 0.001, 'hidden_layer_sizes': 6, 'max_iter': 500, 'random_state': 0, 'solver': 'lbfgs'}\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "准确率为：98.67%\n"
     ]
    }
   ],
   "source": [
    "# 测试iris_predict\n",
    "iris = datasets.load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "test_predict = iris_predict(iris_data, iris_label, iris_data)\n",
    "print(test_predict)\n",
    "# 计算准确率\n",
    "correct = np.sum(test_predict == iris_label)\n",
    "n = len(test_predict)\n",
    "accuracy = correct / n\n",
    "print(\"准确率为：%.2f%%\" % (accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
